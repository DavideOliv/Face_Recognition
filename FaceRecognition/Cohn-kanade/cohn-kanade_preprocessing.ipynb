{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"orig_nbformat":4,"kernelspec":{"name":"python3","display_name":"Python 3.9.2 64-bit"},"interpreter":{"hash":"acc35bc757549bafd0c320377559f878b2b8bdc3ad11380b42473828541f56ee"},"colab":{"name":"cohn-kanade_preprocessing.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"cUDNBdQy0YLd"},"source":["#Preprocessing CK+ dataset\n","In questo notebook generiamo il dataset di addestramento delle reti al riconoscimento delle emozioni facciali.\n","\n","Il dataset che viene creato verra' aumentato utilizzando delle rotazioni nelle immagini e successivamente bilanciato basandoci sulle classi.\n","\n","Creiamo un dataset composto da 4 file di estensione **npy** dove:\n","* **train_dataset** contiene poco piu' di 1000 immagini per il **_train_**,\n","* **train_labels** contiene le **labels** per il train gia' multilabellizzate (ogni riga e' fatta cosi' -> [0,0,0,1,0,0,0,0] con 1 rappresentante la classe di appartenenza),\n","* **test_dataset** contiene poco piu' di 200 immagini per il **_test_**,\n","* **train_labels** come sopra."]},{"cell_type":"markdown","metadata":{"id":"oXnYg6Yy1qav"},"source":["##Import e definizioni\n","In questa sezione vengono effettuate le import delle librerie e la definizione di **costanti, classi e funzioni** utili."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zOigbUQqSohM","executionInfo":{"status":"ok","timestamp":1628246040237,"user_tz":-120,"elapsed":55600,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}},"outputId":"2c24d08c-50dc-4d4e-e349-1b96d70a82b8"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JDxzE9fgSeEh","executionInfo":{"status":"ok","timestamp":1628246041400,"user_tz":-120,"elapsed":1180,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}}},"source":["import os\n","import matplotlib.pyplot as plt \n","import numpy as np \n","import cv2\n","from time import time\n","import random\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"giLNbdlyS-oX","executionInfo":{"status":"ok","timestamp":1628247437827,"user_tz":-120,"elapsed":329,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}},"outputId":"1edcc8b6-9bbd-4294-f850-d845baa8abfb"},"source":["%cd /content/gdrive/MyDrive/BDAMLproject/Cohn-Kanade/Cohn-Kanade\\ Database"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/BDAMLproject/Cohn-Kanade/Cohn-Kanade Database\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X3_Bev7jSeEj","executionInfo":{"status":"ok","timestamp":1628247382423,"user_tz":-120,"elapsed":488,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}}},"source":["path_emotion = \"Emotion\"\n","path_images = \"cohn-kanade-images\"\n","end_emotions = \"_emotion.txt\""],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uxVP1rTV2Bcn"},"source":["###Definizione di DataAugumentator\n","Classe contenente metodi per il data augumentation, vengono effettuate solo rotazioni nella creazione del dataset."]},{"cell_type":"code","metadata":{"id":"8f-ryQTWkarP","executionInfo":{"status":"ok","timestamp":1628247383284,"user_tz":-120,"elapsed":463,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}}},"source":["class DataUgumentator:\n","  def __init__(self):\n","    pass\n","\n","  def horizontal_flip(self, img, flag = True):\n","    if flag:\n","        return cv2.flip(img, 1)\n","    else:\n","        return img\n","  \n","  def vertical_flip(self, img, flag = True):\n","    if flag:\n","        return cv2.flip(img, 0)\n","    else:\n","        return img\n","\n","  def horizontal_shift(self, img, ratio=0.0):\n","    if ratio > 1 or ratio < 0:\n","        print('Value should be less than 1 and greater than 0')\n","        return img\n","    ratio = random.uniform(-ratio, ratio)\n","    h, w = img.shape[:2]\n","    to_shift = w*ratio\n","    if ratio > 0:\n","        img = img[:, :int(w-to_shift), :]\n","    if ratio < 0:\n","        img = img[:, int(-1*to_shift):, :]\n","    img = fill(img, h, w)\n","    return img\n","\n","  def vertical_shift(self, img, ratio=0.0):\n","    if ratio > 1 or ratio < 0:\n","        print('Value should be less than 1 and greater than 0')\n","        return img\n","    ratio = random.uniform(-ratio, ratio)\n","    h, w = img.shape[:2]\n","    to_shift = h*ratio\n","    if ratio > 0:\n","        img = img[:int(h-to_shift), :, :]\n","    if ratio < 0:\n","        img = img[int(-1*to_shift):, :, :]\n","    img = fill(img, h, w)\n","    return img\n","\n","  def zoom(self, img, value):\n","    if value > 1 or value < 0:\n","        print('Value for zoom should be less than 1 and greater than 0')\n","        return img\n","    value = random.uniform(value, 1)\n","    h, w = img.shape[:2]\n","    h_taken = int(value*h)\n","    w_taken = int(value*w)\n","    h_start = random.randint(0, h-h_taken)\n","    w_start = random.randint(0, w-w_taken)\n","    img = img[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n","    img = fill(img, h, w)\n","    return img\n","  \n","  def rotation(self, img, angle):\n","    # angle in gradi\n","    angle = int(random.uniform(-angle, angle))\n","    h, w = img.shape[:2]\n","    M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n","    img = cv2.warpAffine(img, M, (w, h))\n","    return img\n","\n","def timed(func):\n","  def wrapper(*args, **kwds):\n","    start = time()\n","    val = func(*args, **kwds)\n","    print(\"Elapsed time: \", time() - start, \"s\")\n","    return val\n","  return wrapper"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"50-F5Wpb2M1C"},"source":["###Definizione della funzione preprocess\n","effettua il preprocessing del dataset. "]},{"cell_type":"code","metadata":{"id":"Hb2uofKZ1zXB","executionInfo":{"status":"ok","timestamp":1628247386700,"user_tz":-120,"elapsed":302,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}}},"source":["@timed\n","def preprocess(img_dim, list_emotion, rgb=False, neutral=False):\n","  \n","  dataset = {\n","    0 : [], # neutral\n","    1 : [], # anger\n","    2 : [], # contempt\n","    3 : [], # disgust\n","    4 : [], # fear\n","    5 : [], # happy\n","    6 : [], # sadness\n","    7 : [], # surprise\n","  }\n","\n","  for person in list_emotion:\n","    list_person_emotions = os.listdir(path_emotion + \"/\" + person)\n","    for emotion in list_person_emotions:\n","      file = os.listdir(path_emotion + \"/\" + person + \"/\" + emotion)\n","      if len(file) == 0:\n","        continue\n","      else:\n","        with open(path_emotion + \"/\" + person + \"/\" + emotion + \"/\" + file[0], 'r') as f:\n","          label = int(f.read().strip().split(\".\")[0])\n","          list_images = os.listdir(path_images + \"/\" + person + \"/\" + emotion )\n","          if len(list_images) < 4 :\n","            print(\"For path \" + path_images + \"/\" + person + \"/\" + emotion + \" whe have less than 4 images\")\n","            print(\"list imgs\", list_images)\n","          else:\n","            if neutral:\n","              neutral_img = list_images[0]\n","              try:\n","                imn = cv2.imread(path_images + \"/\" + person + \"/\" + emotion + \"/\" + neutral_img)\n","                if not rgb:\n","                  imn = cv2.cvtColor(imn, cv2.COLOR_RGB2GRAY)\n","                imn = cv2.resize(imn, (img_dim,img_dim))\n","                dataset[0].append(imn)\n","              except Exception as e:\n","                print(e)\n","                print(\"for path: \" + path_images + \"/\" + person + \"/\" + emotion)\n","                print(\"img neutral:\", neutral_img)\n","            for img in list_images[-3:]:\n","              try:\n","                im = cv2.imread(path_images + \"/\" + person + \"/\" + emotion + \"/\" + img)\n","                if not rgb:\n","                  im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n","                im = cv2.resize(im, (img_dim,img_dim))\n","                im30 = augument.rotation(im, 30)\n","                im_30 = augument.rotation(im, -30)\n","                dataset[label].append(im)\n","                dataset[label].append(im30)\n","                dataset[label].append(im_30)\n","              except Exception as e:\n","                print(e)\n","                print(\"for path: \" + path_images + \"/\" + person + \"/\" + emotion)\n","                print(\"img list:\", list_images)\n","                print(\"img:\", img)\n","                if img.startswith(\".\"):\n","                  print(\"\\n\\tDeleting:\", img)\n","                  os.remove(path_images + \"/\" + person + \"/\" + emotion + \"/\" + img)\n","                  print(\"\\tdone\\n\")\n","\n","  for key in dataset.keys():\n","    dataset[key] = np.array(dataset[key])\n","\n","  return dataset"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M5QFtYYpSeEk"},"source":["## Preprocessing"]},{"cell_type":"code","metadata":{"id":"b63Jmu3ESeEk","executionInfo":{"status":"ok","timestamp":1628247966894,"user_tz":-120,"elapsed":371,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}}},"source":["list_emotions = os.listdir(path_emotion)\n","list_person_train, list_person_test = train_test_split(list_emotions, shuffle = True, test_size = 0.05)\n","augument = DataUgumentator()"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"_2WtvMVsSeEl","executionInfo":{"status":"ok","timestamp":1628247977508,"user_tz":-120,"elapsed":10264,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}},"outputId":"ccf0555d-bb85-47f5-a955-7fd812d268fd"},"source":["labels_train = {}\n","labels_test = {}\n","\n","dataset_train = preprocess(224, list_person_train, rgb=False, neutral=False)\n","dataset_test = preprocess(224, list_person_test, rgb=False, neutral=False)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Elapsed time:  9.476033449172974 s\n","Elapsed time:  0.6481406688690186 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-derx0oSeEl","executionInfo":{"status":"ok","timestamp":1628247977509,"user_tz":-120,"elapsed":88,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}},"outputId":"6368c941-901d-4611-89dc-3a13a0db16dd"},"source":["print(\"\\nDataset di Train\\n\")\n","for key in dataset_train.keys():\n","  print(f\"\\tOccourrencies for label {key} :\", dataset_train[key].shape[0])\n","  labels_train[key] = np.ones((dataset_train[key].shape[0], 1), dtype=int) * int(key)\n","\n","print(\"\\nDataset di Test\\n\")\n","for key in dataset_test.keys():\n","  print(f\"\\tOccourrencies for label {key} :\", dataset_test[key].shape[0])\n","  labels_test[key] = np.ones((dataset_test[key].shape[0], 1), dtype=int) * int(key)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["\n","Dataset di Train\n","\n","\tOccourrencies for label 0 : 0\n","\tOccourrencies for label 1 : 360\n","\tOccourrencies for label 2 : 153\n","\tOccourrencies for label 3 : 495\n","\tOccourrencies for label 4 : 216\n","\tOccourrencies for label 5 : 594\n","\tOccourrencies for label 6 : 243\n","\tOccourrencies for label 7 : 693\n","\n","Dataset di Test\n","\n","\tOccourrencies for label 0 : 0\n","\tOccourrencies for label 1 : 45\n","\tOccourrencies for label 2 : 9\n","\tOccourrencies for label 3 : 36\n","\tOccourrencies for label 4 : 9\n","\tOccourrencies for label 5 : 27\n","\tOccourrencies for label 6 : 9\n","\tOccourrencies for label 7 : 54\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QKS_LuF5vbDw","executionInfo":{"status":"ok","timestamp":1628247977510,"user_tz":-120,"elapsed":78,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}}},"source":["min_occ = np.min([d.shape[0] for d in dataset_train.values()][1:]) if len(dataset_train[0]) == 0 else np.min([d for d in dataset_train.values()])\n","\n","for key in dataset_train.keys():\n","  dataset_train[key] = dataset_train[key][:min_occ]\n","  labels_train[key] = labels_train[key][:min_occ]"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNam9W73tcTT","executionInfo":{"status":"ok","timestamp":1628247977510,"user_tz":-120,"elapsed":74,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}}},"source":["dataset_list = [d for d in dataset_train.values()][1:] if len(dataset_train[0]) == 0 else [d for d in dataset_train.values()]\n","labels_list = [d for d in labels_train.values()][1:] if len(dataset_train[0]) == 0 else [d for d in labels_train.values()]\n","\n","dataset_tot = np.concatenate(dataset_list)\n","labels_tot = np.concatenate(labels_list)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gi0Oq9P-qCdY","executionInfo":{"status":"ok","timestamp":1628247977511,"user_tz":-120,"elapsed":72,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}}},"source":["min_occ_test = np.min([d.shape[0] for d in dataset_test.values()][1:]) if len(dataset_test[0]) == 0 else np.min([d for d in dataset_test.values()])\n","\n","for key in dataset_test.keys():\n","  dataset_test[key] = dataset_test[key][:min_occ_test]\n","  labels_test[key] = labels_test[key][:min_occ_test]"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"SpJE10WapS8E","executionInfo":{"status":"ok","timestamp":1628247977511,"user_tz":-120,"elapsed":70,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}}},"source":["dataset_test_list = [d for d in dataset_test.values()][1:] if len(dataset_test[0]) == 0 else [d for d in dataset_test.values()]\n","labels_test_list = [d for d in labels_test.values()][1:] if len(dataset_test[0]) == 0 else [d for d in labels_test.values()]\n","\n","dataset_tot_test = np.concatenate(dataset_test_list)\n","labels_tot_test = np.concatenate(labels_test_list)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gV1s_itsSeEn","executionInfo":{"status":"ok","timestamp":1628247977512,"user_tz":-120,"elapsed":71,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}},"outputId":"ffdc9a20-6961-4aee-c6c7-da22cfa22ff4"},"source":["for i in range(8):\n","    print(f\"n_occurences({i}) train = {np.count_nonzero(labels_tot == i)}\" )\n","    print(f\"n_occurences({i}) test = {np.count_nonzero(labels_tot_test == i)}\" )\n","    print()"],"execution_count":30,"outputs":[{"output_type":"stream","text":["n_occurences(0) train = 0\n","n_occurences(0) test = 0\n","\n","n_occurences(1) train = 153\n","n_occurences(1) test = 9\n","\n","n_occurences(2) train = 153\n","n_occurences(2) test = 9\n","\n","n_occurences(3) train = 153\n","n_occurences(3) test = 9\n","\n","n_occurences(4) train = 153\n","n_occurences(4) test = 9\n","\n","n_occurences(5) train = 153\n","n_occurences(5) test = 9\n","\n","n_occurences(6) train = 153\n","n_occurences(6) test = 9\n","\n","n_occurences(7) train = 153\n","n_occurences(7) test = 9\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hfzsFZrhz4Oa","executionInfo":{"status":"ok","timestamp":1628247977512,"user_tz":-120,"elapsed":69,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}}},"source":["encoder = MultiLabelBinarizer()\n","train_labels = encoder.fit_transform(labels_tot)\n","test_labels = encoder.fit_transform(labels_tot_test)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"agJ9ZIneYfQb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628247977513,"user_tz":-120,"elapsed":69,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}},"outputId":"0bcff1bf-675e-4dff-a75b-208b7be138c2"},"source":["train_labels.shape"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1071, 7)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"JYvdKYmG2dgj"},"source":["###Salvataggio dei dataset"]},{"cell_type":"code","metadata":{"id":"tR5juKO1SeEm","executionInfo":{"status":"ok","timestamp":1628247977894,"user_tz":-120,"elapsed":449,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}}},"source":["!rm -r /content/dataset\n","!mkdir /content/dataset\n","\n","np.save(\"/content/dataset/train_dataset.npy\", dataset_tot)\n","np.save(\"/content/dataset/train_labels.npy\", train_labels)\n","np.save(\"/content/dataset/test_dataset.npy\", dataset_tot_test)\n","np.save(\"/content/dataset/test_labels.npy\", test_labels)"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hwxp9ipf2hnX"},"source":["###Salvataggio su Google Drive\n","Occhio ai path (cambiare i nomi)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uNsLaIfc2lSN","executionInfo":{"status":"ok","timestamp":1628247978481,"user_tz":-120,"elapsed":615,"user":{"displayName":"Lorenzo D'Agostino","photoUrl":"","userId":"05269750341157657069"}},"outputId":"d0360d50-9cda-48e9-f960-d45d1b27723c"},"source":["!cp -av /content/dataset /content/gdrive/MyDrive/BDAMLproject/Cohn-Kanade/\n","!mv /content/gdrive/MyDrive/BDAMLproject/Cohn-Kanade/dataset /content/gdrive/MyDrive/BDAMLproject/Cohn-Kanade/dataset_resnet"],"execution_count":34,"outputs":[{"output_type":"stream","text":["'/content/dataset' -> '/content/gdrive/MyDrive/BDAMLproject/Cohn-Kanade/dataset'\n","'/content/dataset/train_dataset.npy' -> '/content/gdrive/MyDrive/BDAMLproject/Cohn-Kanade/dataset/train_dataset.npy'\n","'/content/dataset/train_labels.npy' -> '/content/gdrive/MyDrive/BDAMLproject/Cohn-Kanade/dataset/train_labels.npy'\n","'/content/dataset/test_dataset.npy' -> '/content/gdrive/MyDrive/BDAMLproject/Cohn-Kanade/dataset/test_dataset.npy'\n","'/content/dataset/test_labels.npy' -> '/content/gdrive/MyDrive/BDAMLproject/Cohn-Kanade/dataset/test_labels.npy'\n"],"name":"stdout"}]}]}